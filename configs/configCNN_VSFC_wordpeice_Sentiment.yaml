vocab:
  type: WordPieceTokenizer_VSFC_Sentiment
  path:
    train: data/UIT-VSFC/UIT-VSFC-train.json
    dev: data/UIT-VSFC/UIT-VSFC-dev.json
    test: data/UIT-VSFC/UIT-VSFC-test.json
  min_freq: 5
  model_prefix: "checkpoints/BiGRU_Model6layer_VSFC_wordpeice_Sentiment/BiGRU_Model6layer_VSFC_wordpeice_Sentiment"
  model_type: "word"
  # required for the base vocab

  eos_token: <e>
  unk_token: <u>
  pad_token: <p>
  bos_token: <b>
  space_token: <s>

dataset:
  train: 
    type: UIT_VSFC_Dataset_Sentiment
    path: data/UIT-VSFC/UIT-VSFC-train.json
  dev:
    type: UIT_VSFC_Dataset_Sentiment
    path: data/UIT-VSFC/UIT-VSFC-dev.json
  test: 
    type: UIT_VSFC_Dataset_Sentiment
    path: data/UIT-VSFC/UIT-VSFC-test.json
  batch_size: 32
  num_workers: 4

model:
  name: BiGRU_Model6layer_VSFC_wordpeice_Sentiment
  architecture: CNN_Model
  embed_dim: 300
  num_filters: 100
  d_model: 300
  dropout: 0.2
  output_dim: 3
  kernel_sizes: [3, 4, 5]
  label_smoothing: 0.5
  device: cuda

training:
  checkpoint_path: "checkpoints/BiGRU_Model6layer_VSFC_wordpeice_Sentiment"
  learning_rate: 0.1
  warmup: 1000
  patience: 50
  score: f1

task: lstm_Label_Task