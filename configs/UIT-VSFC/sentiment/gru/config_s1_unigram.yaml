dataset:
  batch_size: 32
  dev:
    path: data/UIT-VSFC/UIT-VSFC-dev.json
    type: UIT_VSFC_Dataset_Topic
  num_workers: 4
  test:
    path: data/UIT-VSFC/UIT-VSFC-test.json
    type: UIT_VSFC_Dataset_Topic
  train:
    path: data/UIT-VSFC/UIT-VSFC-train.json
    type: UIT_VSFC_Dataset_Topic
model:
  architecture: BiGRU_Model
  d_model: 256
  device: cuda
  dropout: 0.2
  hidden_dim: 256
  input_dim: 256
  label_smoothing: 0.5
  layer_dim: 6
  name: BiGRU_Model6layer_VSFC_WordPiece_Topic
  output_dim: 4
task: RNN_Label_Task
training:
  checkpoint_path: checkpoints/UIT_VFSC/Topic/BiGRU/wordpiece
  learning_rate: 0.1
  patience: 10
  score: f1
  seed: 42
  warmup: 1000
vocab:
  bos_token: <b>
  eos_token: <e>
  min_freq: 5
  model_prefix: ''
  model_type: unigram
  pad_token: <p>
  path:
    dev: data/UIT-VSFC/UIT-VSFC-dev.json
    test: data/UIT-VSFC/UIT-VSFC-test.json
    train: data/UIT-VSFC/UIT-VSFC-train.json
  path1: checkpoints/UIT_VFSC/Topic/
  path2: /BiGRU/wordpiece/vsfc_wordpiece
  schema: 1
  space_token: <s>
  type: WordPieceTokenizer_VSFC_Topic
  unk_token: <u>
  vocab_size: 230
